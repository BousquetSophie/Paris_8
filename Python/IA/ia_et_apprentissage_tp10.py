# -*- coding: utf-8 -*-
"""IA_et_apprentissage_TP10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VWoqqcXpI36h_-aYzMJhSWD3RpwgQ6Dq
"""

!pip install accelerate -U
!pip install transformers -U
!pip install datasets -U

!pip install -q peft transformers datasets evaluate

import torch
import transformers
import datasets

train_dataset, validation_dataset = datasets.load_dataset("glue", "sst2", split=["train", "validation"])
tokenizer = transformers.AutoTokenizer.from_pretrained("microsoft/deberta-v3-base")
model = transformers.AutoModelForSequenceClassification.from_pretrained("microsoft/deberta-v3-base")

import peft

peft_config = peft.PromptEncoderConfig(task_type="SEQ_CLS", num_virtual_tokens=20, encoder_hidden_size=128)
model = peft.get_peft_model(model, peft_config)
model.print_trainable_parameters()

# On définit la fonction de preprocessing qu'on va appliquer à nos deux datasets
def preprocess(dataset):
    """

    :param dataset: Un objet Dataset HuggingFace contenant notre jeu de données. Doit posséder au moins une colonne
    "sentence" contenant du texte à tokenizer
    :return: Un objet Dataset HuggingFace contenant toutes les colonnes du Dataset d'entrée, plus les sorties du
    tokenizer. Contient en particulier une colonne 'input_ids' avec les versions tokenizée des phrases d'entrée
    """

    # On commence par définir la transformation que l'on veut appliquer à un bloc de ligne d'un dataset donné. Cette
    # Fonction prend en entrée un dictionnaire, dont les clés correspondent aux colonnes de nos datasets, et dont les
    # valeurs correspondent à une liste de valeurs de chaque colonne.

    def tokenize_batch(batch):
        """

        :param batch: Un dictionnaire dont les clés correspondent aux colonne de dataset, et dont les valeurs
        correspondantes sont des listes d'éléments des colonnes correspondantes
        :return: Un dictionnaire avec de nouvelles clés correpondant aux nouvelles colonnes du dataset, et dont les
        valeurs correspondantes sont des lite de transformées des valeurs d'entrées
        """
        # Dans cette fonction, on cherche simplement à tokenizer les phrases présentes dans la liste
        # batch['sentence']. On va également les tronquer à 128 tokens, pour éviter d'avoir des séquences d'entrées
        # trop longues
        pre_out = tokenizer(
            batch['sentence'],  # la liste de string que l'on veut tokenizer
            max_length=128,  # la longueur maximale que l'on accepte pour une séquence de tokens,
            truncation='longest_first'  # La façon dont le tokenizer doit couper les séquences trop longues
        )

        return pre_out

    # On applique la fonction encode_batch de manière distribuée à notre dataset en appelant la méthode .map
    new_dataset = dataset.map(
        tokenize_batch,  # Le Callable que l'on souhaite appliqué à notre dataset
        batched=True,  # Indique si l'on veut exécuter le Callable sur des blocs de lignes du dataset ou ligne par ligne
    )

    # On renomme la colonne du Dataset contenant notre variable à prédire "labels" pour éviter les confusions avec le
    # trainer huggingface
    new_dataset = new_dataset.rename_column("label", "labels")
    new_dataset = new_dataset.remove_columns([x for x in new_dataset.column_names if x not in ['labels', 'input_ids']])

    return new_dataset


def compute_metric_fn(eval_predictions):
    """
    Calcule les métriques d'évaluation du modèle.

    :param eval_predictions: Un objet huggingface EvalPrediction, constitué de deux attributs 'predictions', et 'label_ids'
    correspondant respectivement aux prédictions du modèle et aux véritables valeurs des variables à prédire
    :return: Un dictionnaire python, contenant des couples clés/valeurs avec le nom de la métrique, puis sa valeur
    """

    # On sort les predictions de l'objet EvalPrediction d'entrée
    predictions = eval_predictions.predictions

    # On sort les valeurs des variables explicatives de l'objet EvalPrediction d'entrée
    labels = eval_predictions.label_ids

    # On choisit la prédiction du modèle comme l'état de la variable à prédire associé à la plus haute probabilité
    predictions = predictions.argmax(-1)

    # On calcule la quantité moyenne de prédictions correctes
    accuracy = (predictions == labels).mean()

    # On instancie notre dictionnaire de métriques (qui contient içi une métrique)
    metric_dictionary = {"accuracy": accuracy}

    return metric_dictionary

tokenized_train_dataset = preprocess(train_dataset)
tokenized_validation_dataset = preprocess(validation_dataset)

training_args = transformers.TrainingArguments(
    output_dir="output_dir",  # Le répertoire dans lequel le Trainer écrira tout un tas d'infos sur l'ajustement
    learning_rate=1e-5,  # Le pas d'apprentissage de la descente de gradient, choisi un peu arbitrairement
    num_train_epochs=5,  # Le nombre d'epoch que durera l'ajustement du modèle
    per_device_train_batch_size=16,  # Le nombre d'observation qu'on tirera au sort pour effectuer chaque itération de la descente de gradient stochastique
    per_device_eval_batch_size=128, # Permet de faire l'évaluation des performances sur le jeu de test en plusieurs étapes pour éviter les problèmes de mémoire
    evaluation_strategy='epoch',  # Indique au Trainer si vous voulez évaluer les performances du modèle toutes les epochs, ou après un certain nombre d'itération de descente
    eval_steps=10,  # Si vous avez choisi 'steps' en evaluation_strategy, indique la fréquence à laquelle vous voulez évaluer les performances du modèle
    remove_unused_columns=False,  # Important de le mettre en False, sinon ca marche pas. J'ai jamais compris à quoi ca servait
    save_strategy='no',  # Indique si vous voulez sauvegarder votre modèle dans 'output_dir'. Je mets 'no' parceque ici je veux pas enregistrer de modèles
)

# On peut maintenant instancier notre CustomTrainer!
trainer = transformers.Trainer(
    model=model,  # Indique au trainer quel modèle on cherche à ajuster
    args=training_args,  # Indique au trainer tous les comportements qu'on a spécifié dans training_args
    train_dataset=tokenized_train_dataset,  # Indique au trainer le jeu de données à utiliser pour ajuster model
    eval_dataset=tokenized_validation_dataset,  # Indique au trainer le jeu de données à utiliser pour évaluer model
    compute_metrics=compute_metric_fn,
    data_collator=transformers.DataCollatorWithPadding(tokenizer)  # Indique au modèle qu'il va avoir besoin de mettre du padding sur les séquences d'entrée pour en faire des Tensor
)

trainer.train()
