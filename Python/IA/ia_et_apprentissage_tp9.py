# -*- coding: utf-8 -*-
"""IA_et_apprentissage_TP9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B16TRskfew8h8l2oLpAfrBrAZJ4nnTUA
"""

!pip install transformers -U
!pip install datasets -U

!pip install accelerate -U

import torch
from torchvision.datasets import MNIST
import matplotlib
import matplotlib.pyplot as plt
from transformers import Trainer, TrainingArguments
import numpy as np
from datasets import Dataset

dataset = MNIST(root='.', download=True, train=True)
test_dataset = MNIST(root='.', download=True, train=False)

# Convert the data and targets to numpy arrays for easier manipulation
images, labels = dataset.data.numpy(), dataset.targets.numpy()
test_images, test_labels = test_dataset.data.numpy(), test_dataset.targets.numpy()

images = images / 255
test_images = test_images / 255

# Prepare the data in a dictionary format
data = {'inputs': images[:, np.newaxis], 'labels': images[:, np.newaxis]}
test_data = {'inputs': test_images[:, np.newaxis], 'labels': test_images[:, np.newaxis]}


train_dataset = Dataset.from_dict(data)
test_dataset = Dataset.from_dict(test_data)


class ConvolutionAutoEncoder(torch.nn.Module):

  def __init__(self, hidden_size, bottleneck_size):
    super(ConvolutionAutoEncoder, self).__init__()
    self.encoder = torch.nn.Sequential(
          torch.nn.Conv2d(in_channels=1, out_channels=hidden_size//4, kernel_size=5, stride=2),
          torch.nn.GELU(),
          torch.nn.Conv2d(in_channels=hidden_size//4, out_channels=hidden_size//2, kernel_size=5, stride=2),
          torch.nn.GELU(),
          torch.nn.Conv2d(in_channels=hidden_size//2, out_channels=hidden_size, kernel_size=4, stride=2),
          torch.nn.GELU(),
          torch.nn.Flatten(),
          torch.nn.Linear(in_features=hidden_size, out_features=bottleneck_size)
    )

    self.decoder = torch.nn.Sequential(
          torch.nn.ConvTranspose2d(in_channels=bottleneck_size, out_channels=hidden_size, kernel_size=4, stride=2),
          torch.nn.GELU(),
          torch.nn.ConvTranspose2d(in_channels=hidden_size, out_channels=hidden_size//2, kernel_size=6, stride=2),
          torch.nn.GELU(),
          torch.nn.ConvTranspose2d(in_channels=hidden_size//2, out_channels=hidden_size//4, kernel_size=6, stride=2),
          torch.nn.GELU(),
          torch.nn.Conv2d(in_channels=hidden_size//4, out_channels=1, kernel_size=1, stride=1),
          torch.nn.Sigmoid()
    )

  def forward(self, inputs):
    encoded_inputs = self.encoder(inputs)

    encoded_inputs = encoded_inputs.unsqueeze(-1).unsqueeze(-1)

    reconstruted_inputs = self.decoder(encoded_inputs)

    return reconstruted_inputs


class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.get("labels")
        outputs = model(inputs.get("inputs"))
        loss = torch.nn.MSELoss()(outputs, labels)

        return (loss, outputs) if return_outputs else loss

    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):

        with torch.no_grad():
            labels = inputs.get("labels")
            logits = model(inputs.get("inputs"))
            loss = torch.nn.MSELoss()(logits, labels)

        return (loss, logits, labels)

my_model = ConvolutionAutoEncoder(hidden_size=32, bottleneck_size=2)

training_args = TrainingArguments(
    output_dir = 'output_dir',
    learning_rate=.01,
    num_train_epochs=20,
    per_device_train_batch_size=64,
    per_device_eval_batch_size=500,
    evaluation_strategy='steps',
    eval_steps=200,
    remove_unused_columns=False,
    logging_steps=10,
    save_strategy='no'
)

trainer = CustomTrainer(
    model = my_model,
    args = training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset
)

trainer.train()

